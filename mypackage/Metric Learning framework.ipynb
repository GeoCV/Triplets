{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from Utils import *\n",
    "\n",
    "from algorithms import *\n",
    "from new_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparison of algorithms for ordinal embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create data|\n",
    "dimensions= 3\n",
    "number_of_points= 30\n",
    "\n",
    "X = np.random.random((number_of_points, dimensions))\n",
    "X = center_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:3 \n",
      "Number of points:30 \n",
      "Pulls:7344\n",
      "\n",
      "TRAIN:  5875\n",
      "TEST:  1469\n"
     ]
    }
   ],
   "source": [
    "n,d = X.shape\n",
    "pulls = 20*int(number_of_points*dimensions*np.log(number_of_points))\n",
    "split_percentage = 0.8\n",
    "\n",
    "# NOISE RUINS EVERYTHING, talk to blake about how to measure acc in this case\n",
    "# winner, loser, head\n",
    "tot_triplets, error = getTriplets(X, int(pulls*(2-split_percentage)), noise=False) \n",
    "\n",
    "\n",
    "triplets = tot_triplets[:int(len(tot_triplets)*split_percentage)]\n",
    "test_triplets = tot_triplets[int(len(tot_triplets)*split_percentage):]\n",
    "\n",
    "print('Dimensions:{} \\nNumber of points:{} \\nPulls:{}'.format(dimensions,number_of_points, len(tot_triplets)))\n",
    "print()\n",
    "print('TRAIN: ', len(triplets))\n",
    "print('TEST: ', len(test_triplets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def predictX(X_true, X_predict, test_triplets):\n",
    "    \n",
    "    true = []\n",
    "    pred = []\n",
    "    for q in test_triplets:\n",
    "        \n",
    "        true_label = np.sign(scoreX(X_true, q, 1))\n",
    "        pred_label = np.sign(scoreX(X_predict, q, 1))\n",
    "        \n",
    "        true.append(true_label)\n",
    "        pred.append(pred_label)\n",
    "    \n",
    "    acc = accuracy_score(true, pred)\n",
    "    print(\"Correctly predicted {0:.2f} % of the unseen triplets\".format(acc*100))    \n",
    "    \n",
    "    return acc\n",
    "\n",
    "def predictM(M_true, M_predict, test_triplets):\n",
    "    \n",
    "    true = []\n",
    "    pred = []\n",
    "    for q in test_triplets:\n",
    "        \n",
    "        true_label = np.sign(scoreM(M_true, q, 1))\n",
    "        pred_label = np.sign(scoreM(M_predict, q, 1))\n",
    "        \n",
    "        true.append(true_label)\n",
    "        pred.append(pred_label)\n",
    "    \n",
    "    acc = accuracy_score(true, pred)\n",
    "    print(\"Correctly predicted {0:.2f} % of the unseen triplets\".format(acc*100))    \n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from projected_gradient import *\n",
    "\n",
    "# M, loss, proj_grad_loss_arr = computeEmbedding(M0,\n",
    "#                 n,\n",
    "#                  d,\n",
    "#                  triplets,\n",
    "#                  num_random_restarts=0,Å“\n",
    "#                  max_iter_GD=500,\n",
    "#                  max_norm=1,\n",
    "#                  epsilon=0.0001,\n",
    "#                  accuracy=accuracy, \n",
    "#                  verbose=False)\n",
    "\n",
    "# from crowd_kernel import *\n",
    "# X, emp_loss_train, projection_free_loss_arr = computeEmbedding(n,d,triplets,alpha=1,\n",
    "#                                     num_random_restarts=0,\n",
    "#                                     epsilon=0.0001,\n",
    "#                                     accuracy = accuracy,\n",
    "#                                     max_iters=100,\n",
    "#                                     verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.005  ,  0.02875,  0.0525 ,  0.07625,  0.1    ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons = np.linspace(0.005, 0.1,5)\n",
    "epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Step size was too big, halving it. Iteration #:  4\n",
      "Step size was too big, halving it. Iteration #:  4\n",
      "No progress\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# Non Convex \n",
    "exp = 0\n",
    "X0 = np.random.random((n,d))\n",
    "stats_non_convex_single_exp_full_gd = triplet_algorithms(ste_loss, \n",
    "                           triplets,\n",
    "                           X0,                       \n",
    "                           d,\n",
    "                           'full_grad', \n",
    "                           50,\n",
    "                           iters=500,\n",
    "                           epsilon = epsilons[exp],\n",
    "                           proj=None,\n",
    "                           debug=False\n",
    "                          )\n",
    "\n",
    "X_hat = stats_non_convex_single_exp['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted 96.24 % of the unseen triplets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96241830065359479"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictX(X, X_hat, test_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "EPOCH: 1 LOG ERROR 0.7339942611433395 Emp error 0.29616013071895425\n",
      "EPOCH: 2 LOG ERROR 0.48114973397651545 Emp error 0.22038398692810457\n",
      "EPOCH: 3 LOG ERROR 0.4437245246492277 Emp error 0.2079248366013072\n",
      "EPOCH: 4 LOG ERROR 0.47498822205921193 Emp error 0.2042483660130719\n",
      "EPOCH: 5 LOG ERROR 0.37258010059274166 Emp error 0.16891339869281047\n",
      "EPOCH: 6 LOG ERROR 0.32261055421846946 Emp error 0.14501633986928106\n",
      "EPOCH: 7 LOG ERROR 0.2561700297888174 Emp error 0.11254084967320262\n",
      "EPOCH: 8 LOG ERROR 0.20807870074058538 Emp error 0.0900735294117647\n",
      "EPOCH: 9 LOG ERROR 0.17210887348844273 Emp error 0.05984477124183007\n",
      "EPOCH: 10 LOG ERROR 0.14938635241649603 Emp error 0.041666666666666664\n",
      "EPOCH: 11 LOG ERROR 0.13574891069992098 Emp error 0.031862745098039214\n",
      "EPOCH: 12 LOG ERROR 0.12787507154518132 Emp error 0.02185457516339869\n",
      "EPOCH: 13 LOG ERROR 0.1233936283918938 Emp error 0.020016339869281044\n",
      "EPOCH: 14 LOG ERROR 0.12049326611570624 Emp error 0.01838235294117647\n",
      "EPOCH: 15 LOG ERROR 0.11827299186408255 Emp error 0.017565359477124183\n",
      "EPOCH: 16 LOG ERROR 0.116363141223162 Emp error 0.016748366013071895\n",
      "EPOCH: 17 LOG ERROR 0.11463545769528631 Emp error 0.015727124183006536\n",
      "EPOCH: 18 LOG ERROR 0.1130440166721343 Emp error 0.015522875816993464\n",
      "EPOCH: 19 LOG ERROR 0.11156671269454259 Emp error 0.013684640522875817\n",
      "EPOCH: 20 LOG ERROR 0.1101894016702183 Emp error 0.013684640522875817\n",
      "EPOCH: 21 LOG ERROR 0.10890194189965935 Emp error 0.013684640522875817\n",
      "EPOCH: 22 LOG ERROR 0.10769282290035075 Emp error 0.013276143790849673\n",
      "EPOCH: 23 LOG ERROR 0.10655417594995786 Emp error 0.012867647058823529\n",
      "EPOCH: 24 LOG ERROR 0.10547936152390402 Emp error 0.012254901960784314\n",
      "EPOCH: 25 LOG ERROR 0.10446267673060908 Emp error 0.012254901960784314\n",
      "EPOCH: 26 LOG ERROR 0.10349917302432979 Emp error 0.012254901960784314\n",
      "EPOCH: 27 LOG ERROR 0.10258451992734775 Emp error 0.011642156862745098\n",
      "EPOCH: 28 LOG ERROR 0.10171490027289876 Emp error 0.012050653594771242\n",
      "EPOCH: 29 LOG ERROR 0.10088692810091637 Emp error 0.011437908496732025\n",
      "EPOCH: 30 LOG ERROR 0.10009758326084933 Emp error 0.011437908496732025\n",
      "EPOCH: 31 LOG ERROR 0.09934415859665602 Emp error 0.011233660130718954\n",
      "EPOCH: 32 LOG ERROR 0.0986242167780014 Emp error 0.011029411764705883\n",
      "EPOCH: 33 LOG ERROR 0.09793555464236102 Emp error 0.011029411764705883\n",
      "EPOCH: 34 LOG ERROR 0.09727617346566271 Emp error 0.01082516339869281\n",
      "EPOCH: 35 LOG ERROR 0.09664425396933297 Emp error 0.010212418300653595\n",
      "EPOCH: 36 LOG ERROR 0.09603813515230951 Emp error 0.010212418300653595\n",
      "EPOCH: 37 LOG ERROR 0.09545629624196802 Emp error 0.010212418300653595\n",
      "EPOCH: 38 LOG ERROR 0.09489734121050891 Emp error 0.010212418300653595\n",
      "EPOCH: 39 LOG ERROR 0.09435998541826632 Emp error 0.010212418300653595\n",
      "EPOCH: 40 LOG ERROR 0.0938430440330914 Emp error 0.010212418300653595\n",
      "EPOCH: 41 LOG ERROR 0.09334542194259127 Emp error 0.010008169934640522\n",
      "EPOCH: 42 LOG ERROR 0.09286610492874688 Emp error 0.010008169934640522\n",
      "EPOCH: 43 LOG ERROR 0.09240415191595883 Emp error 0.010008169934640522\n",
      "EPOCH: 44 LOG ERROR 0.09195868813653009 Emp error 0.010008169934640522\n",
      "EPOCH: 45 LOG ERROR 0.09152889908400613 Emp error 0.010008169934640522\n",
      "EPOCH: 46 LOG ERROR 0.09111402514609139 Emp error 0.010008169934640522\n",
      "EPOCH: 47 LOG ERROR 0.09071335682616424 Emp error 0.010008169934640522\n",
      "EPOCH: 48 LOG ERROR 0.09032623047657382 Emp error 0.010008169934640522\n",
      "EPOCH: 49 LOG ERROR 0.08995202447852765 Emp error 0.010008169934640522\n",
      "EPOCH: 50 LOG ERROR 0.08959015581302897 Emp error 0.010008169934640522\n",
      "EPOCH: 51 LOG ERROR 0.08924007697532359 Emp error 0.010008169934640522\n",
      "EPOCH: 52 LOG ERROR 0.08890127319202128 Emp error 0.010008169934640522\n",
      "EPOCH: 53 LOG ERROR 0.08857325990566746 Emp error 0.010008169934640522\n",
      "EPOCH: 54 LOG ERROR 0.0882555804963035 Emp error 0.010008169934640522\n",
      "EPOCH: 55 LOG ERROR 0.08794780421354725 Emp error 0.010008169934640522\n",
      "EPOCH: 56 LOG ERROR 0.08764952429616617 Emp error 0.010008169934640522\n",
      "EPOCH: 57 LOG ERROR 0.0873603562590136 Emp error 0.010008169934640522\n",
      "EPOCH: 58 LOG ERROR 0.08707993632969371 Emp error 0.010008169934640522\n",
      "EPOCH: 59 LOG ERROR 0.08680792001948542 Emp error 0.010008169934640522\n",
      "EPOCH: 60 LOG ERROR 0.08654398081487745 Emp error 0.010008169934640522\n",
      "EPOCH: 61 LOG ERROR 0.08628780897768563 Emp error 0.010008169934640522\n",
      "EPOCH: 62 LOG ERROR 0.08603911044310143 Emp error 0.010008169934640522\n",
      "EPOCH: 63 LOG ERROR 0.08579760580622674 Emp error 0.010008169934640522\n",
      "EPOCH: 64 LOG ERROR 0.08556302938870335 Emp error 0.010008169934640522\n",
      "EPOCH: 65 LOG ERROR 0.0853351283779545 Emp error 0.00980392156862745\n",
      "EPOCH: 66 LOG ERROR 0.08511366203237665 Emp error 0.00980392156862745\n",
      "EPOCH: 67 LOG ERROR 0.08489840094650948 Emp error 0.00959967320261438\n",
      "EPOCH: 68 LOG ERROR 0.08468912637084519 Emp error 0.00959967320261438\n",
      "EPOCH: 69 LOG ERROR 0.08448562958148308 Emp error 0.00959967320261438\n",
      "EPOCH: 70 LOG ERROR 0.08428771129530968 Emp error 0.00959967320261438\n",
      "EPOCH: 71 LOG ERROR 0.08409518112684239 Emp error 0.00959967320261438\n",
      "EPOCH: 72 LOG ERROR 0.0839078570832188 Emp error 0.00959967320261438\n",
      "EPOCH: 73 LOG ERROR 0.08372556509417993 Emp error 0.00959967320261438\n",
      "EPOCH: 74 LOG ERROR 0.0835481385741873 Emp error 0.00959967320261438\n",
      "EPOCH: 75 LOG ERROR 0.0833754180140793 Emp error 0.00959967320261438\n",
      "EPOCH: 76 LOG ERROR 0.0832072505999202 Emp error 0.00959967320261438\n",
      "EPOCH: 77 LOG ERROR 0.0830434898569055 Emp error 0.00959967320261438\n",
      "EPOCH: 78 LOG ERROR 0.08288399531638134 Emp error 0.00959967320261438\n",
      "EPOCH: 79 LOG ERROR 0.08272863220421034 Emp error 0.00959967320261438\n",
      "EPOCH: 80 LOG ERROR 0.08257727114886658 Emp error 0.009395424836601307\n",
      "EPOCH: 81 LOG ERROR 0.08242978790779358 Emp error 0.009395424836601307\n",
      "EPOCH: 82 LOG ERROR 0.08228606311067346 Emp error 0.009395424836601307\n",
      "EPOCH: 83 LOG ERROR 0.0821459820183751 Emp error 0.009395424836601307\n",
      "EPOCH: 84 LOG ERROR 0.08200943429645695 Emp error 0.009395424836601307\n",
      "EPOCH: 85 LOG ERROR 0.08187631380218174 Emp error 0.009395424836601307\n",
      "EPOCH: 86 LOG ERROR 0.0817465183840994 Emp error 0.009395424836601307\n",
      "EPOCH: 87 LOG ERROR 0.08161994969332072 Emp error 0.009395424836601307\n",
      "EPOCH: 88 LOG ERROR 0.08149651300567846 Emp error 0.009395424836601307\n",
      "EPOCH: 89 LOG ERROR 0.08137611705403053 Emp error 0.009395424836601307\n",
      "EPOCH: 90 LOG ERROR 0.0812586738700367 Emp error 0.009395424836601307\n",
      "EPOCH: 91 LOG ERROR 0.0811440986347597 Emp error 0.009395424836601307\n",
      "EPOCH: 92 LOG ERROR 0.08103230953752665 Emp error 0.009395424836601307\n",
      "EPOCH: 93 LOG ERROR 0.0809232276425015 Emp error 0.009395424836601307\n",
      "EPOCH: 94 LOG ERROR 0.08081677676247484 Emp error 0.009395424836601307\n",
      "EPOCH: 95 LOG ERROR 0.08071288333941606 Emp error 0.009395424836601307\n",
      "EPOCH: 96 LOG ERROR 0.08061147633135146 Emp error 0.009395424836601307\n",
      "EPOCH: 97 LOG ERROR 0.08051248710517737 Emp error 0.009395424836601307\n",
      "EPOCH: 98 LOG ERROR 0.08041584933504298 Emp error 0.009395424836601307\n",
      "EPOCH: 99 LOG ERROR 0.08032149890595953 Emp error 0.009395424836601307\n",
      "EPOCH: 100 LOG ERROR 0.08022937382231551 Emp error 0.009395424836601307\n",
      "EPOCH: 101 LOG ERROR 0.08013941412101185 Emp error 0.009395424836601307\n",
      "EPOCH: 102 LOG ERROR 0.08005156178892855 Emp error 0.009191176470588236\n",
      "EPOCH: 103 LOG ERROR 0.07996576068448369 Emp error 0.009191176470588236\n",
      "EPOCH: 104 LOG ERROR 0.07988195646303003 Emp error 0.009191176470588236\n",
      "EPOCH: 105 LOG ERROR 0.07980009650587985 Emp error 0.009191176470588236\n",
      "EPOCH: 106 LOG ERROR 0.07972012985274138 Emp error 0.009191176470588236\n",
      "EPOCH: 107 LOG ERROR 0.07964200713737675 Emp error 0.009191176470588236\n",
      "EPOCH: 108 LOG ERROR 0.07956568052629959 Emp error 0.009191176470588236\n",
      "EPOCH: 109 LOG ERROR 0.07949110366034486 Emp error 0.009191176470588236\n",
      "EPOCH: 110 LOG ERROR 0.0794182315989438 Emp error 0.009191176470588236\n",
      "EPOCH: 111 LOG ERROR 0.07934702076696848 Emp error 0.009191176470588236\n",
      "EPOCH: 112 LOG ERROR 0.0792774289039953 Emp error 0.008986928104575163\n",
      "EPOCH: 113 LOG ERROR 0.0792094150158603 Emp error 0.008986928104575163\n",
      "EPOCH: 114 LOG ERROR 0.07914293932839139 Emp error 0.008986928104575163\n",
      "EPOCH: 115 LOG ERROR 0.07907796324318646 Emp error 0.008986928104575163\n",
      "EPOCH: 116 LOG ERROR 0.07901444929534529 Emp error 0.008986928104575163\n",
      "EPOCH: 117 LOG ERROR 0.07895236111304559 Emp error 0.008986928104575163\n",
      "EPOCH: 118 LOG ERROR 0.07889166337886878 Emp error 0.008986928104575163\n",
      "EPOCH: 119 LOG ERROR 0.07883232179278883 Emp error 0.008986928104575163\n",
      "EPOCH: 120 LOG ERROR 0.07877430303673355 Emp error 0.008986928104575163\n",
      "EPOCH: 121 LOG ERROR 0.0787175747406481 Emp error 0.008986928104575163\n",
      "EPOCH: 122 LOG ERROR 0.07866210544997593 Emp error 0.008986928104575163\n",
      "EPOCH: 123 LOG ERROR 0.07860786459449433 Emp error 0.008986928104575163\n",
      "EPOCH: 124 LOG ERROR 0.07855482245843351 Emp error 0.008986928104575163\n",
      "EPOCH: 125 LOG ERROR 0.07850295015181855 Emp error 0.008986928104575163\n",
      "EPOCH: 126 LOG ERROR 0.07845221958297603 Emp error 0.008986928104575163\n",
      "EPOCH: 127 LOG ERROR 0.07840260343214357 Emp error 0.008986928104575163\n",
      "EPOCH: 128 LOG ERROR 0.07835407512613815 Emp error 0.008986928104575163\n",
      "EPOCH: 129 LOG ERROR 0.07830660881402846 Emp error 0.008986928104575163\n",
      "EPOCH: 130 LOG ERROR 0.07826017934375994 Emp error 0.008986928104575163\n",
      "EPOCH: 131 LOG ERROR 0.07821476223969895 Emp error 0.008986928104575163\n",
      "EPOCH: 132 LOG ERROR 0.07817033368104354 Emp error 0.008986928104575163\n",
      "EPOCH: 133 LOG ERROR 0.07812687048106433 Emp error 0.008986928104575163\n",
      "EPOCH: 134 LOG ERROR 0.07808435006713965 Emp error 0.008986928104575163\n",
      "EPOCH: 135 LOG ERROR 0.07804275046154707 Emp error 0.008986928104575163\n",
      "EPOCH: 136 LOG ERROR 0.07800205026297567 Emp error 0.008986928104575163\n",
      "EPOCH: 137 LOG ERROR 0.07796222862873317 Emp error 0.008986928104575163\n",
      "EPOCH: 138 LOG ERROR 0.0779232652576074 Emp error 0.008986928104575163\n",
      "EPOCH: 139 LOG ERROR 0.07788514037336097 Emp error 0.008782679738562092\n",
      "EPOCH: 140 LOG ERROR 0.0778478347088328 Emp error 0.008782679738562092\n",
      "EPOCH: 141 LOG ERROR 0.07781132949060968 Emp error 0.008782679738562092\n",
      "EPOCH: 142 LOG ERROR 0.07777560642425624 Emp error 0.008782679738562092\n",
      "EPOCH: 143 LOG ERROR 0.07774064768007126 Emp error 0.008782679738562092\n",
      "EPOCH: 144 LOG ERROR 0.07770643587934953 Emp error 0.008782679738562092\n",
      "EPOCH: 145 LOG ERROR 0.07767295408112981 Emp error 0.008782679738562092\n",
      "EPOCH: 146 LOG ERROR 0.07764018576940664 Emp error 0.008782679738562092\n",
      "EPOCH: 147 LOG ERROR 0.0776081148407887 Emp error 0.008782679738562092\n",
      "EPOCH: 148 LOG ERROR 0.0775767255925818 Emp error 0.008782679738562092\n",
      "EPOCH: 149 LOG ERROR 0.07754600271128456 Emp error 0.008782679738562092\n",
      "EPOCH: 150 LOG ERROR 0.07751593126147314 Emp error 0.008782679738562092\n",
      "EPOCH: 151 LOG ERROR 0.07748649667506505 Emp error 0.00857843137254902\n",
      "EPOCH: 152 LOG ERROR 0.07745768474094462 Emp error 0.00857843137254902\n",
      "EPOCH: 153 LOG ERROR 0.07742948159493541 Emp error 0.00857843137254902\n",
      "EPOCH: 154 LOG ERROR 0.07740187371010471 Emp error 0.00857843137254902\n",
      "EPOCH: 155 LOG ERROR 0.07737484788738991 Emp error 0.00857843137254902\n",
      "EPOCH: 156 LOG ERROR 0.07734839124653281 Emp error 0.00857843137254902\n",
      "EPOCH: 157 LOG ERROR 0.07732249121730936 Emp error 0.00857843137254902\n",
      "EPOCH: 158 LOG ERROR 0.0772971355310434 Emp error 0.00857843137254902\n",
      "EPOCH: 159 LOG ERROR 0.07727231221239275 Emp error 0.00857843137254902\n",
      "EPOCH: 160 LOG ERROR 0.0772480095714013 Emp error 0.00857843137254902\n",
      "EPOCH: 161 LOG ERROR 0.07722421619580253 Emp error 0.00857843137254902\n",
      "EPOCH: 162 LOG ERROR 0.07720092094356562 Emp error 0.00857843137254902\n",
      "EPOCH: 163 LOG ERROR 0.07717811293567646 Emp error 0.00857843137254902\n",
      "EPOCH: 164 LOG ERROR 0.07715578154914628 Emp error 0.00857843137254902\n",
      "EPOCH: 165 LOG ERROR 0.07713391641023444 Emp error 0.00857843137254902\n",
      "EPOCH: 166 LOG ERROR 0.07711250738788494 Emp error 0.00857843137254902\n",
      "EPOCH: 167 LOG ERROR 0.07709154458735795 Emp error 0.00857843137254902\n",
      "EPOCH: 168 LOG ERROR 0.07707101834406276 Emp error 0.00857843137254902\n",
      "EPOCH: 169 LOG ERROR 0.07705091921757494 Emp error 0.00857843137254902\n",
      "EPOCH: 170 LOG ERROR 0.07703123798583267 Emp error 0.008169934640522876\n",
      "EPOCH: 171 LOG ERROR 0.07701196563950954 Emp error 0.008169934640522876\n",
      "EPOCH: 172 LOG ERROR 0.07699309337655783 Emp error 0.008169934640522876\n",
      "EPOCH: 173 LOG ERROR 0.07697461259690538 Emp error 0.008169934640522876\n",
      "EPOCH: 174 LOG ERROR 0.07695651489731953 Emp error 0.008169934640522876\n",
      "EPOCH: 175 LOG ERROR 0.0769387920664148 Emp error 0.008169934640522876\n",
      "EPOCH: 176 LOG ERROR 0.07692143607980931 Emp error 0.008169934640522876\n",
      "EPOCH: 177 LOG ERROR 0.07690443909542116 Emp error 0.008169934640522876\n",
      "EPOCH: 178 LOG ERROR 0.07688779344890193 Emp error 0.008169934640522876\n",
      "EPOCH: 179 LOG ERROR 0.07687149164919788 Emp error 0.008169934640522876\n",
      "EPOCH: 180 LOG ERROR 0.07685552637424635 Emp error 0.008169934640522876\n",
      "EPOCH: 181 LOG ERROR 0.07683989046678388 Emp error 0.008169934640522876\n",
      "EPOCH: 182 LOG ERROR 0.07682457693028212 Emp error 0.008169934640522876\n",
      "EPOCH: 183 LOG ERROR 0.076809578924992 Emp error 0.008169934640522876\n",
      "EPOCH: 184 LOG ERROR 0.07679488976410509 Emp error 0.008169934640522876\n",
      "EPOCH: 185 LOG ERROR 0.07678050291001472 Emp error 0.008169934640522876\n",
      "EPOCH: 186 LOG ERROR 0.07676641197068736 Emp error 0.008169934640522876\n",
      "EPOCH: 187 LOG ERROR 0.07675261069613168 Emp error 0.008169934640522876\n",
      "EPOCH: 188 LOG ERROR 0.07673909297496281 Emp error 0.008169934640522876\n",
      "EPOCH: 189 LOG ERROR 0.07672585283106524 Emp error 0.008169934640522876\n",
      "EPOCH: 190 LOG ERROR 0.07671288442034246 Emp error 0.008169934640522876\n",
      "EPOCH: 191 LOG ERROR 0.076700182027558 Emp error 0.008169934640522876\n",
      "EPOCH: 192 LOG ERROR 0.07668774006325729 Emp error 0.008169934640522876\n",
      "EPOCH: 193 LOG ERROR 0.07667555306077847 Emp error 0.008169934640522876\n",
      "EPOCH: 194 LOG ERROR 0.07666361567333808 Emp error 0.008169934640522876\n",
      "EPOCH: 195 LOG ERROR 0.07665192267119665 Emp error 0.008169934640522876\n",
      "EPOCH: 196 LOG ERROR 0.07664046893890035 Emp error 0.008169934640522876\n",
      "EPOCH: 197 LOG ERROR 0.07662924947259088 Emp error 0.008169934640522876\n",
      "EPOCH: 198 LOG ERROR 0.07661825937739314 Emp error 0.008169934640522876\n",
      "EPOCH: 199 LOG ERROR 0.07660749386486587 Emp error 0.008169934640522876\n",
      "EPOCH: 200 LOG ERROR 0.07659694825052092 Emp error 0.008169934640522876\n",
      "EPOCH: 201 LOG ERROR 0.07658661795140692 Emp error 0.008169934640522876\n",
      "EPOCH: 202 LOG ERROR 0.07657649848375449 Emp error 0.008169934640522876\n",
      "EPOCH: 203 LOG ERROR 0.07656658546068171 Emp error 0.008169934640522876\n",
      "EPOCH: 204 LOG ERROR 0.07655687458996399 Emp error 0.008169934640522876\n",
      "EPOCH: 205 LOG ERROR 0.07654736167185075 Emp error 0.008169934640522876\n",
      "EPOCH: 206 LOG ERROR 0.0765380425969481 Emp error 0.008169934640522876\n",
      "EPOCH: 207 LOG ERROR 0.07652891334414633 Emp error 0.008169934640522876\n",
      "EPOCH: 208 LOG ERROR 0.07651996997860905 Emp error 0.008169934640522876\n",
      "EPOCH: 209 LOG ERROR 0.07651120864980358 Emp error 0.008169934640522876\n",
      "EPOCH: 210 LOG ERROR 0.07650262558958693 Emp error 0.008169934640522876\n",
      "EPOCH: 211 LOG ERROR 0.07649421711033795 Emp error 0.008169934640522876\n",
      "EPOCH: 212 LOG ERROR 0.07648597960313558 Emp error 0.008169934640522876\n",
      "EPOCH: 213 LOG ERROR 0.07647790953598167 Emp error 0.008169934640522876\n",
      "EPOCH: 214 LOG ERROR 0.07647000345207061 Emp error 0.008169934640522876\n",
      "EPOCH: 215 LOG ERROR 0.07646225796809776 Emp error 0.008169934640522876\n",
      "EPOCH: 216 LOG ERROR 0.07645466977261121 Emp error 0.008169934640522876\n",
      "EPOCH: 217 LOG ERROR 0.07644723562440556 Emp error 0.008169934640522876\n",
      "EPOCH: 218 LOG ERROR 0.07643995235095256 Emp error 0.008169934640522876\n",
      "EPOCH: 219 LOG ERROR 0.07643281684686905 Emp error 0.008169934640522876\n",
      "EPOCH: 220 LOG ERROR 0.07642582607242607 Emp error 0.008169934640522876\n",
      "EPOCH: 221 LOG ERROR 0.07641897705209008 Emp error 0.008169934640522876\n",
      "EPOCH: 222 LOG ERROR 0.07641226687310063 Emp error 0.008169934640522876\n",
      "EPOCH: 223 LOG ERROR 0.07640569268408205 Emp error 0.008169934640522876\n",
      "EPOCH: 224 LOG ERROR 0.0763992516936911 Emp error 0.008169934640522876\n",
      "EPOCH: 225 LOG ERROR 0.07639294116928999 Emp error 0.008169934640522876\n",
      "EPOCH: 226 LOG ERROR 0.07638675843565955 Emp error 0.008169934640522876\n",
      "EPOCH: 227 LOG ERROR 0.0763807008737354 Emp error 0.008169934640522876\n",
      "EPOCH: 228 LOG ERROR 0.07637476591938022 Emp error 0.008169934640522876\n",
      "EPOCH: 229 LOG ERROR 0.07636895106217954 Emp error 0.008169934640522876\n",
      "EPOCH: 230 LOG ERROR 0.0763632538442707 Emp error 0.008169934640522876\n",
      "EPOCH: 231 LOG ERROR 0.07635767185919437 Emp error 0.008169934640522876\n",
      "EPOCH: 232 LOG ERROR 0.0763522027507782 Emp error 0.008169934640522876\n",
      "EPOCH: 233 LOG ERROR 0.0763468442120415 Emp error 0.008169934640522876\n",
      "EPOCH: 234 LOG ERROR 0.07634159398412994 Emp error 0.008169934640522876\n",
      "EPOCH: 235 LOG ERROR 0.07633644985527074 Emp error 0.008169934640522876\n",
      "EPOCH: 236 LOG ERROR 0.07633140965975502 Emp error 0.008169934640522876\n",
      "EPOCH: 237 LOG ERROR 0.07632647127694293 Emp error 0.008169934640522876\n",
      "EPOCH: 238 LOG ERROR 0.07632163263029032 Emp error 0.008169934640522876\n",
      "EPOCH: 239 LOG ERROR 0.07631689168640113 Emp error 0.008169934640522876\n",
      "EPOCH: 240 LOG ERROR 0.07631224645409573 Emp error 0.008169934640522876\n",
      "EPOCH: 241 LOG ERROR 0.07630769498350785 Emp error 0.008169934640522876\n",
      "EPOCH: 242 LOG ERROR 0.07630323536519557 Emp error 0.008169934640522876\n",
      "EPOCH: 243 LOG ERROR 0.07629886572927624 Emp error 0.008169934640522876\n",
      "EPOCH: 244 LOG ERROR 0.07629458424458037 Emp error 0.008169934640522876\n",
      "EPOCH: 245 LOG ERROR 0.0762903891178247 Emp error 0.008169934640522876\n",
      "EPOCH: 246 LOG ERROR 0.07628627859280135 Emp error 0.008169934640522876\n",
      "EPOCH: 247 LOG ERROR 0.07628225094959136 Emp error 0.008169934640522876\n",
      "EPOCH: 248 LOG ERROR 0.0762783045037888 Emp error 0.008169934640522876\n",
      "EPOCH: 249 LOG ERROR 0.07627443760574809 Emp error 0.008169934640522876\n",
      "EPOCH: 250 LOG ERROR 0.07627064863984244 Emp error 0.008169934640522876\n",
      "EPOCH: 251 LOG ERROR 0.07626693602374551 Emp error 0.008169934640522876\n",
      "EPOCH: 252 LOG ERROR 0.07626329820772568 Emp error 0.008169934640522876\n",
      "EPOCH: 253 LOG ERROR 0.07625973367395279 Emp error 0.008169934640522876\n",
      "EPOCH: 254 LOG ERROR 0.07625624093582657 Emp error 0.008169934640522876\n",
      "EPOCH: 255 LOG ERROR 0.07625281853731704 Emp error 0.008169934640522876\n",
      "EPOCH: 256 LOG ERROR 0.07624946505231694 Emp error 0.008169934640522876\n",
      "EPOCH: 257 LOG ERROR 0.07624617908401454 Emp error 0.008169934640522876\n",
      "EPOCH: 258 LOG ERROR 0.07624295926427391 Emp error 0.008169934640522876\n",
      "EPOCH: 259 LOG ERROR 0.07623980425303205 Emp error 0.008169934640522876\n",
      "EPOCH: 260 LOG ERROR 0.07623671273771127 Emp error 0.008169934640522876\n",
      "EPOCH: 261 LOG ERROR 0.0762336834326397 Emp error 0.008169934640522876\n",
      "EPOCH: 262 LOG ERROR 0.07623071507848735 Emp error 0.008169934640522876\n",
      "EPOCH: 263 LOG ERROR 0.0762278064417152 Emp error 0.008169934640522876\n",
      "EPOCH: 264 LOG ERROR 0.0762249563140333 Emp error 0.008169934640522876\n",
      "EPOCH: 265 LOG ERROR 0.07622216351187523 Emp error 0.008169934640522876\n",
      "EPOCH: 266 LOG ERROR 0.07621942687587875 Emp error 0.008169934640522876\n",
      "EPOCH: 267 LOG ERROR 0.07621674527038154 Emp error 0.008169934640522876\n",
      "EPOCH: 268 LOG ERROR 0.07621411758292687 Emp error 0.008169934640522876\n",
      "EPOCH: 269 LOG ERROR 0.0762115427237793 Emp error 0.008169934640522876\n",
      "EPOCH: 270 LOG ERROR 0.07620901962545193 Emp error 0.008169934640522876\n",
      "EPOCH: 271 LOG ERROR 0.07620654724224275 Emp error 0.008169934640522876\n",
      "EPOCH: 272 LOG ERROR 0.07620412454978147 Emp error 0.008169934640522876\n",
      "EPOCH: 273 LOG ERROR 0.07620175054458674 Emp error 0.008169934640522876\n",
      "EPOCH: 274 LOG ERROR 0.07619942424363181 Emp error 0.008169934640522876\n",
      "EPOCH: 275 LOG ERROR 0.07619714468392003 Emp error 0.008169934640522876\n",
      "EPOCH: 276 LOG ERROR 0.07619491092207065 Emp error 0.008169934640522876\n",
      "EPOCH: 277 LOG ERROR 0.07619272203391002 Emp error 0.008169934640522876\n",
      "EPOCH: 278 LOG ERROR 0.07619057711407644 Emp error 0.008169934640522876\n",
      "EPOCH: 279 LOG ERROR 0.07618847527562889 Emp error 0.008169934640522876\n",
      "EPOCH: 280 LOG ERROR 0.07618641564966652 Emp error 0.008169934640522876\n",
      "EPOCH: 281 LOG ERROR 0.0761843973849566 Emp error 0.008169934640522876\n",
      "EPOCH: 282 LOG ERROR 0.0761824196475687 Emp error 0.008169934640522876\n",
      "EPOCH: 283 LOG ERROR 0.07618048162051867 Emp error 0.008169934640522876\n",
      "EPOCH: 284 LOG ERROR 0.0761785825034174 Emp error 0.008169934640522876\n",
      "EPOCH: 285 LOG ERROR 0.07617672151212992 Emp error 0.008169934640522876\n",
      "EPOCH: 286 LOG ERROR 0.07617489787843985 Emp error 0.008169934640522876\n",
      "EPOCH: 287 LOG ERROR 0.07617311084972231 Emp error 0.008169934640522876\n",
      "EPOCH: 288 LOG ERROR 0.0761713596886232 Emp error 0.008169934640522876\n",
      "EPOCH: 289 LOG ERROR 0.07616964367274318 Emp error 0.008169934640522876\n",
      "EPOCH: 290 LOG ERROR 0.07616796209433313 Emp error 0.008169934640522876\n",
      "EPOCH: 291 LOG ERROR 0.07616631425999015 Emp error 0.008169934640522876\n",
      "EPOCH: 292 LOG ERROR 0.07616469949036568 Emp error 0.008169934640522876\n",
      "EPOCH: 293 LOG ERROR 0.0761631171198753 Emp error 0.008169934640522876\n",
      "EPOCH: 294 LOG ERROR 0.07616156649641656 Emp error 0.008169934640522876\n",
      "EPOCH: 295 LOG ERROR 0.07616004698109331 Emp error 0.008169934640522876\n",
      "EPOCH: 296 LOG ERROR 0.07615855794794514 Emp error 0.008169934640522876\n",
      "EPOCH: 297 LOG ERROR 0.07615709878368032 Emp error 0.008169934640522876\n",
      "EPOCH: 298 LOG ERROR 0.07615566888741901 Emp error 0.008169934640522876\n",
      "EPOCH: 299 LOG ERROR 0.07615426767043841 Emp error 0.008169934640522876\n",
      "EPOCH: 300 LOG ERROR 0.076152894555923 Emp error 0.008169934640522876\n",
      "EPOCH: 301 LOG ERROR 0.07615154897872245 Emp error 0.008169934640522876\n",
      "EPOCH: 302 LOG ERROR 0.07615023038511255 Emp error 0.008169934640522876\n",
      "EPOCH: 303 LOG ERROR 0.07614893823256187 Emp error 0.008169934640522876\n",
      "EPOCH: 304 LOG ERROR 0.07614767198950358 Emp error 0.008169934640522876\n",
      "EPOCH: 305 LOG ERROR 0.07614643113511045 Emp error 0.008169934640522876\n",
      "EPOCH: 306 LOG ERROR 0.07614521515907766 Emp error 0.008169934640522876\n",
      "EPOCH: 307 LOG ERROR 0.07614402356140614 Emp error 0.008169934640522876\n",
      "EPOCH: 308 LOG ERROR 0.0761428558521935 Emp error 0.008169934640522876\n",
      "EPOCH: 309 LOG ERROR 0.07614171155142938 Emp error 0.008169934640522876\n",
      "EPOCH: 310 LOG ERROR 0.07614059018879077 Emp error 0.008169934640522876\n",
      "EPOCH: 311 LOG ERROR 0.0761394913034479 Emp error 0.008169934640522876\n",
      "EPOCH: 312 LOG ERROR 0.07613841444386932 Emp error 0.008169934640522876\n",
      "EPOCH: 313 LOG ERROR 0.07613735916763285 Emp error 0.008169934640522876\n",
      "EPOCH: 314 LOG ERROR 0.07613632504124129 Emp error 0.008169934640522876\n",
      "EPOCH: 315 LOG ERROR 0.07613531163993936 Emp error 0.008169934640522876\n",
      "EPOCH: 316 LOG ERROR 0.07613431854753706 Emp error 0.008169934640522876\n",
      "EPOCH: 317 LOG ERROR 0.07613334535623446 Emp error 0.008169934640522876\n",
      "EPOCH: 318 LOG ERROR 0.0761323916664529 Emp error 0.008169934640522876\n",
      "EPOCH: 319 LOG ERROR 0.07613145708666683 Emp error 0.008169934640522876\n",
      "EPOCH: 320 LOG ERROR 0.07613054123324044 Emp error 0.008169934640522876\n",
      "EPOCH: 321 LOG ERROR 0.07612964373026741 Emp error 0.008169934640522876\n",
      "EPOCH: 322 LOG ERROR 0.0761287642094151 Emp error 0.008169934640522876\n",
      "EPOCH: 323 LOG ERROR 0.07612790230976925 Emp error 0.008169934640522876\n",
      "EPOCH: 324 LOG ERROR 0.07612705767768478 Emp error 0.008169934640522876\n",
      "EPOCH: 325 LOG ERROR 0.076126229966637 Emp error 0.008169934640522876\n",
      "EPOCH: 326 LOG ERROR 0.07612541883708032 Emp error 0.008169934640522876\n",
      "EPOCH: 327 LOG ERROR 0.07612462395630291 Emp error 0.008169934640522876\n",
      "EPOCH: 328 LOG ERROR 0.07612384499829088 Emp error 0.008169934640522876\n",
      "EPOCH: 329 LOG ERROR 0.07612308164359202 Emp error 0.008169934640522876\n",
      "EPOCH: 330 LOG ERROR 0.07612233357918105 Emp error 0.008169934640522876\n",
      "EPOCH: 331 LOG ERROR 0.07612160049833396 Emp error 0.008169934640522876\n",
      "EPOCH: 332 LOG ERROR 0.07612088210049554 Emp error 0.008169934640522876\n",
      "EPOCH: 333 LOG ERROR 0.07612017809115734 Emp error 0.008169934640522876\n",
      "EPOCH: 334 LOG ERROR 0.07611948818173525 Emp error 0.008169934640522876\n",
      "EPOCH: 335 LOG ERROR 0.07611881208944882 Emp error 0.008169934640522876\n",
      "EPOCH: 336 LOG ERROR 0.0761181495372038 Emp error 0.008169934640522876\n",
      "EPOCH: 337 LOG ERROR 0.07611750025347788 Emp error 0.008169934640522876\n",
      "EPOCH: 338 LOG ERROR 0.07611686397220842 Emp error 0.008169934640522876\n",
      "EPOCH: 339 LOG ERROR 0.0761162404326802 Emp error 0.008169934640522876\n",
      "EPOCH: 340 LOG ERROR 0.07611562937942022 Emp error 0.008169934640522876\n",
      "EPOCH: 341 LOG ERROR 0.07611503056208943 Emp error 0.008169934640522876\n",
      "EPOCH: 342 LOG ERROR 0.07611444373537969 Emp error 0.008169934640522876\n",
      "EPOCH: 343 LOG ERROR 0.07611386865891323 Emp error 0.008169934640522876\n",
      "EPOCH: 344 LOG ERROR 0.07611330509714168 Emp error 0.008169934640522876\n",
      "EPOCH: 345 LOG ERROR 0.0761127528192487 Emp error 0.008169934640522876\n",
      "EPOCH: 346 LOG ERROR 0.0761122115990559 Emp error 0.008169934640522876\n",
      "EPOCH: 347 LOG ERROR 0.07611168121492888 Emp error 0.008169934640522876\n",
      "EPOCH: 348 LOG ERROR 0.07611116144968247 Emp error 0.008169934640522876\n",
      "EPOCH: 349 LOG ERROR 0.07611065209049589 Emp error 0.008169934640522876\n",
      "EPOCH: 350 LOG ERROR 0.07611015292882176 Emp error 0.008169934640522876\n",
      "EPOCH: 351 LOG ERROR 0.0761096637603011 Emp error 0.008169934640522876\n",
      "EPOCH: 352 LOG ERROR 0.07610918438467719 Emp error 0.008169934640522876\n",
      "EPOCH: 353 LOG ERROR 0.07610871460571385 Emp error 0.008169934640522876\n",
      "EPOCH: 354 LOG ERROR 0.0761082542311161 Emp error 0.008169934640522876\n",
      "EPOCH: 355 LOG ERROR 0.07610780307244787 Emp error 0.008169934640522876\n",
      "EPOCH: 356 LOG ERROR 0.0761073609450569 Emp error 0.008169934640522876\n",
      "EPOCH: 357 LOG ERROR 0.07610692766799618 Emp error 0.008169934640522876\n",
      "EPOCH: 358 LOG ERROR 0.0761065030639503 Emp error 0.008169934640522876\n",
      "EPOCH: 359 LOG ERROR 0.0761060869591632 Emp error 0.008169934640522876\n",
      "EPOCH: 360 LOG ERROR 0.07610567918336514 Emp error 0.008169934640522876\n",
      "EPOCH: 361 LOG ERROR 0.07610527956970319 Emp error 0.008169934640522876\n",
      "EPOCH: 362 LOG ERROR 0.07610488795467248 Emp error 0.008169934640522876\n",
      "EPOCH: 363 LOG ERROR 0.07610450417804732 Emp error 0.008169934640522876\n",
      "EPOCH: 364 LOG ERROR 0.07610412808281997 Emp error 0.008169934640522876\n",
      "EPOCH: 365 LOG ERROR 0.07610375951512771 Emp error 0.008169934640522876\n",
      "EPOCH: 366 LOG ERROR 0.07610339832419794 Emp error 0.008169934640522876\n",
      "EPOCH: 367 LOG ERROR 0.07610304436228052 Emp error 0.008169934640522876\n",
      "EPOCH: 368 LOG ERROR 0.07610269748459028 Emp error 0.008169934640522876\n",
      "EPOCH: 369 LOG ERROR 0.07610235754924384 Emp error 0.008169934640522876\n",
      "EPOCH: 370 LOG ERROR 0.07610202441720564 Emp error 0.008169934640522876\n",
      "EPOCH: 371 LOG ERROR 0.07610169795222631 Emp error 0.008169934640522876\n",
      "EPOCH: 372 LOG ERROR 0.07610137802079066 Emp error 0.008169934640522876\n",
      "EPOCH: 373 LOG ERROR 0.07610106449205868 Emp error 0.008169934640522876\n",
      "EPOCH: 374 LOG ERROR 0.0761007572378149 Emp error 0.008169934640522876\n",
      "EPOCH: 375 LOG ERROR 0.07610045613241469 Emp error 0.008169934640522876\n",
      "EPOCH: 376 LOG ERROR 0.0761001610527328 Emp error 0.008169934640522876\n",
      "EPOCH: 377 LOG ERROR 0.07609987187811115 Emp error 0.008169934640522876\n",
      "EPOCH: 378 LOG ERROR 0.07609958849031155 Emp error 0.008169934640522876\n",
      "EPOCH: 379 LOG ERROR 0.0760993107734654 Emp error 0.008169934640522876\n",
      "EPOCH: 380 LOG ERROR 0.07609903861402703 Emp error 0.008169934640522876\n",
      "EPOCH: 381 LOG ERROR 0.07609877190072616 Emp error 0.008169934640522876\n",
      "EPOCH: 382 LOG ERROR 0.07609851052452417 Emp error 0.008169934640522876\n",
      "EPOCH: 383 LOG ERROR 0.07609825437856613 Emp error 0.008169934640522876\n",
      "EPOCH: 384 LOG ERROR 0.07609800335813961 Emp error 0.008169934640522876\n",
      "EPOCH: 385 LOG ERROR 0.07609775736063094 Emp error 0.008169934640522876\n",
      "EPOCH: 386 LOG ERROR 0.07609751628548152 Emp error 0.008169934640522876\n",
      "EPOCH: 387 LOG ERROR 0.07609728003414898 Emp error 0.008169934640522876\n",
      "EPOCH: 388 LOG ERROR 0.07609704851006543 Emp error 0.008169934640522876\n",
      "EPOCH: 389 LOG ERROR 0.0760968216185986 Emp error 0.008169934640522876\n",
      "EPOCH: 390 LOG ERROR 0.07609659926701032 Emp error 0.008169934640522876\n",
      "EPOCH: 391 LOG ERROR 0.07609638136442268 Emp error 0.008169934640522876\n",
      "EPOCH: 392 LOG ERROR 0.07609616782177692 Emp error 0.008169934640522876\n",
      "EPOCH: 393 LOG ERROR 0.0760959585517996 Emp error 0.008169934640522876\n",
      "EPOCH: 394 LOG ERROR 0.07609575346896627 Emp error 0.008169934640522876\n",
      "EPOCH: 395 LOG ERROR 0.076095552489464 Emp error 0.008169934640522876\n",
      "EPOCH: 396 LOG ERROR 0.07609535553116008 Emp error 0.008169934640522876\n",
      "EPOCH: 397 LOG ERROR 0.076095162513567 Emp error 0.008169934640522876\n",
      "EPOCH: 398 LOG ERROR 0.07609497335780878 Emp error 0.008169934640522876\n",
      "EPOCH: 399 LOG ERROR 0.07609478798659051 Emp error 0.008169934640522876\n",
      "EPOCH: 400 LOG ERROR 0.07609460632416548 Emp error 0.008169934640522876\n",
      "EPOCH: 401 LOG ERROR 0.0760944282963023 Emp error 0.008169934640522876\n",
      "EPOCH: 402 LOG ERROR 0.07609425383025877 Emp error 0.008169934640522876\n",
      "EPOCH: 403 LOG ERROR 0.07609408285474782 Emp error 0.008169934640522876\n",
      "EPOCH: 404 LOG ERROR 0.07609391529991101 Emp error 0.008169934640522876\n",
      "EPOCH: 405 LOG ERROR 0.0760937510972889 Emp error 0.008169934640522876\n",
      "EPOCH: 406 LOG ERROR 0.07609359017979284 Emp error 0.008169934640522876\n",
      "EPOCH: 407 LOG ERROR 0.07609343248167798 Emp error 0.008169934640522876\n",
      "EPOCH: 408 LOG ERROR 0.07609327793851553 Emp error 0.008169934640522876\n",
      "EPOCH: 409 LOG ERROR 0.0760931264871677 Emp error 0.008169934640522876\n",
      "EPOCH: 410 LOG ERROR 0.0760929780657598 Emp error 0.008169934640522876\n",
      "EPOCH: 411 LOG ERROR 0.07609283261365699 Emp error 0.008169934640522876\n",
      "EPOCH: 412 LOG ERROR 0.07609269007143883 Emp error 0.008169934640522876\n",
      "EPOCH: 413 LOG ERROR 0.07609255038087422 Emp error 0.008169934640522876\n",
      "EPOCH: 414 LOG ERROR 0.0760924134848976 Emp error 0.008169934640522876\n",
      "EPOCH: 415 LOG ERROR 0.07609227932758661 Emp error 0.008169934640522876\n",
      "EPOCH: 416 LOG ERROR 0.07609214785413929 Emp error 0.008169934640522876\n",
      "EPOCH: 417 LOG ERROR 0.07609201901084874 Emp error 0.008169934640522876\n",
      "EPOCH: 418 LOG ERROR 0.0760918927450852 Emp error 0.008169934640522876\n",
      "EPOCH: 419 LOG ERROR 0.07609176900527163 Emp error 0.008169934640522876\n",
      "EPOCH: 420 LOG ERROR 0.07609164774086397 Emp error 0.008169934640522876\n",
      "EPOCH: 421 LOG ERROR 0.07609152890232995 Emp error 0.008169934640522876\n",
      "No progress\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# CONVEX STE FULL GRAD Single experiment\n",
    "M0 = X0 @ X0.T\n",
    "stats_convex_single_exp = triplet_algorithms(ste_loss_convex, \n",
    "                       triplets,\n",
    "                       M0,                       \n",
    "                       d,                            \n",
    "                       'full_grad', \n",
    "                        300,\n",
    "                       iters=5000,\n",
    "                       epsilon =epsilons[exp],\n",
    "                       proj=projected_psd,\n",
    "                       debug= True)\n",
    "    \n",
    "M_hat = stats_convex_single_exp['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted 96.90 % of the unseen triplets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96895424836601307"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictM(X @ X.T, M_hat, test_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FUll Experimental setup\n",
    "stats_non_convex = []\n",
    "for epsilon in epsilons:\n",
    "    print('Epsilon', epsilon)\n",
    "    X0 = np.random.random((n,d))\n",
    "    stats1= triplet_algorithms(ste_loss, \n",
    "                       triplets,\n",
    "                       X0,                       \n",
    "                       d,\n",
    "                       'full_grad', \n",
    "                       20,\n",
    "                       iters=1000,\n",
    "                       epsilon = epsilon,\n",
    "                       proj=None,\n",
    "                       debug=False)\n",
    "    \n",
    "    stats_non_convex.append(stats1)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment number i.e which level of accuracy \n",
    "df = pd.DataFrame([\n",
    "#         stats_convex[3]['emp'],\n",
    "                   stats_non_convex[exp]['emp'],\n",
    "#                    stats3['emp'],\n",
    "#                     list(np.array(stats4['emp'])[epoch_inds])\n",
    "                  ]).T\n",
    "\n",
    "df.columns = [\n",
    "#     'Proj Grad: Full GD (constant stepsize, shrink each epoch)',\n",
    "              'Non convex: Full GD (constant stepsize, shrink each epoch)', \n",
    "#               'Proj Grad: SGD (constant stepsize)',\n",
    "#               'Non Convex: SGD (constant stepsize, shrink each epoch)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Epochs', fontsize=22)\n",
    "ax.set_title('Epsilon= {}'.format(epsilons[exp]), fontsize=22)\n",
    "ax.legend(fontsize=18);\n",
    "\n",
    "df = []\n",
    "for i in stats_non_convex:\n",
    "    df.append(sum(i['time_per_iter']))\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex FULL GD'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Non Convex SGD\n",
    "exp = 2\n",
    "stats_non_convex_sgd = triplet_algorithms(ste_loss, \n",
    "                           triplets,\n",
    "                           X0,                       \n",
    "                           d,\n",
    "                           'sgd', \n",
    "                           0.2,\n",
    "                           iters=5000,\n",
    "                           epsilon = epsilons[exp],\n",
    "                           proj=None,\n",
    "                           debug=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONVEX STE FULL GRAD Full exp set up\n",
    "M0 = X0 @ X0.T\n",
    "stats_convex = []\n",
    "for epsilon in epsilons:\n",
    "    stats2 = triplet_algorithms(ste_loss_convex, \n",
    "                       triplets,\n",
    "                       M0,                       \n",
    "                       d,                            \n",
    "                       'full_grad', \n",
    "                        600,\n",
    "                       iters=5000,\n",
    "                       epsilon =epsilon,\n",
    "                       proj=projected,\n",
    "                       debug= False)\n",
    "    \n",
    "    stats_convex.append(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in stats_convex:\n",
    "    df.append(sum(i['time_per_iter']))\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats3 = triplet_algorithms(ste_loss_convex, \n",
    "#                             triplets,\n",
    "#                             M0,                       \n",
    "#                             d,                            \n",
    "#                             'sgd', \n",
    "#                             3,\n",
    "#                             iters=5000,\n",
    "#                             epsilon = 0.07625,\n",
    "#                             proj=projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats2['emp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_inds = np.linspace(0, len(stats4['emp'])-1, stats4['epoch_count'], dtype=int)\n",
    "\n",
    "df = pd.DataFrame([stats_convex[3]['emp'],\n",
    "                   stats_non_convex[3]['emp'],\n",
    "#                    stats3['emp'],\n",
    "                    list(np.array(stats4['emp'])[epoch_inds])\n",
    "                  ]).T\n",
    "df.columns = ['Proj Grad: Full GD (constant stepsize, shrink each epoch)',\n",
    "              'Non convex: Full GD (constant stepsize, shrink each epoch)', \n",
    "#               'Proj Grad: SGD (constant stepsize)',\n",
    "              'Non Convex: SGD (constant stepsize, shrink each epoch)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Epochs', fontsize=22)\n",
    "ax.set_title('Epsilon= {}'.format(0.07625), fontsize=22)\n",
    "ax.legend(fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "#                 stats2['emp'],\n",
    "#                 stats1['emp'],\n",
    "                   stats3['emp'],\n",
    "                   stats4['emp'],                   \n",
    "                  ]\n",
    "                 ).T\n",
    "df.columns = [\n",
    "#     'Proj Grad: Full GD (constant stepsize)',\n",
    "#               'Non convex full gradient descent (constant stepsize)', \n",
    "              'Proj Grad: SGD (constant stepsize)',\n",
    "              'Non Convex: SGD (constant stepsize)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Iterations of full gradient descent', fontsize=22)\n",
    "ax.legend(fontsize=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(stats1['time_per_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(stats2['time_per_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for i,j in zip(stats_non_convex,stats_convex):\n",
    "    df.append([sum(i['time_per_iter']), len(j['emp'])*stats_convex[0]['avg_time_per_iter']])\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex', 'Convex- with projection'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     print(len(stats_convex[i]['emp']))\n",
    "#     print(stats_convex[i]['time_per_iter'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
