{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from Utils import *\n",
    "\n",
    "from algorithms import *\n",
    "from new_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Comparison of algorithms for ordinal embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create data|\n",
    "dimensions= 3\n",
    "number_of_points= 30\n",
    "\n",
    "X = np.random.random((number_of_points, dimensions))\n",
    "X = center_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:3 \n",
      "Number of points:30 \n",
      "Pulls:6120\n"
     ]
    }
   ],
   "source": [
    "n,d = X.shape\n",
    "pulls = 20*int(number_of_points*dimensions*np.log(number_of_points))\n",
    "print('Dimensions:{} \\nNumber of points:{} \\nPulls:{}'.format(dimensions,number_of_points, pulls))\n",
    "# NOISE RUINS EVERYTHING, talk to blake about how to measure acc in this case\n",
    "triplets, error = getTriplets(X, pulls, noise=False) \n",
    "    \n",
    "# print(ste_loss(X, triplets,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from projected_gradient import *\n",
    "\n",
    "# M, loss, proj_grad_loss_arr = computeEmbedding(M0,\n",
    "#                 n,\n",
    "#                  d,\n",
    "#                  triplets,\n",
    "#                  num_random_restarts=0,\n",
    "#                  max_iter_GD=500,\n",
    "#                  max_norm=1,\n",
    "#                  epsilon=0.0001,\n",
    "#                  accuracy=accuracy, \n",
    "#                  verbose=False)\n",
    "\n",
    "# from crowd_kernel import *\n",
    "# X, emp_loss_train, projection_free_loss_arr = computeEmbedding(n,d,triplets,alpha=1,\n",
    "#                                     num_random_restarts=0,\n",
    "#                                     epsilon=0.0001,\n",
    "#                                     accuracy = accuracy,\n",
    "#                                     max_iters=100,\n",
    "#                                     verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.005  ,  0.02875,  0.0525 ,  0.07625,  0.1    ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilons = np.linspace(0.005, 0.1,5)\n",
    "epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LOG ERROR 0.6158448586362282 Emp error 0.33905228758169936\n",
      "1 LOG ERROR 0.5736130717058344 Emp error 0.26633986928104575\n",
      "2 LOG ERROR 1.3970326363928718 Emp error 0.28888888888888886\n",
      "3 LOG ERROR 17.10811478456113 Emp error 0.3277777777777778\n",
      "Step size was too big, halving it. Iteration #:  4\n",
      "Step size was too big, halving it. Iteration #:  4\n",
      "4 LOG ERROR 1.1828723122642366 Emp error 0.19754901960784313\n",
      "5 LOG ERROR 0.26564418176651555 Emp error 0.10326797385620914\n",
      "6 LOG ERROR 0.18990167308048803 Emp error 0.06993464052287582\n",
      "7 LOG ERROR 0.1562725066590288 Emp error 0.04918300653594771\n",
      "Accuracy reached in 7 iterations\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "# Non Convex SGD\n",
    "exp = 5\n",
    "X0 = np.random.random((n,d))\n",
    "stats_non_convex_single_exp = triplet_algorithms(ste_loss, \n",
    "                           triplets,\n",
    "                           X0,                       \n",
    "                           d,\n",
    "                           'full_grad', \n",
    "                           50,\n",
    "                           iters=5000,\n",
    "                           epsilon = epsilons[exp],\n",
    "                           proj=None,\n",
    "                           debug=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LOG ERROR 0.9443539259633825 Emp error 0.49297385620915035\n",
      "1 LOG ERROR 0.9015613729450095 Emp error 0.4883986928104575\n",
      "2 LOG ERROR 0.8646125229025555 Emp error 0.48480392156862745\n",
      "3 LOG ERROR 0.8330066898368208 Emp error 0.48251633986928105\n",
      "4 LOG ERROR 0.8061826490468137 Emp error 0.47794117647058826\n",
      "5 LOG ERROR 0.7835565532603386 Emp error 0.4759803921568627\n",
      "6 LOG ERROR 0.7645580782003931 Emp error 0.4722222222222222\n",
      "7 LOG ERROR 0.7486579286679454 Emp error 0.47058823529411764\n",
      "8 LOG ERROR 0.7353829497872144 Emp error 0.46797385620915033\n",
      "9 LOG ERROR 0.724319102934068 Emp error 0.4642156862745098\n",
      "10 LOG ERROR 0.7151058960644184 Emp error 0.4609477124183007\n",
      "11 LOG ERROR 0.7074275222266702 Emp error 0.4553921568627451\n",
      "12 LOG ERROR 0.7010054458912074 Emp error 0.45408496732026143\n",
      "13 LOG ERROR 0.6955947657415764 Emp error 0.4491830065359477\n",
      "14 LOG ERROR 0.690983857605497 Emp error 0.4452614379084967\n",
      "15 LOG ERROR 0.6869953985889973 Emp error 0.43594771241830066\n",
      "16 LOG ERROR 0.6834872728306279 Emp error 0.4290849673202614\n",
      "17 LOG ERROR 0.6803526599988605 Emp error 0.42401960784313725\n",
      "18 LOG ERROR 0.6775185285269175 Emp error 0.425\n",
      "19 LOG ERROR 0.6749413362035301 Emp error 0.4196078431372549\n",
      "20 LOG ERROR 0.6725995321722323 Emp error 0.41568627450980394\n",
      "21 LOG ERROR 0.6704844115932543 Emp error 0.41323529411764703\n",
      "22 LOG ERROR 0.6685918731050202 Emp error 0.40816993464052287\n",
      "23 LOG ERROR 0.6669166515639395 Emp error 0.4047385620915033\n",
      "24 LOG ERROR 0.6654491961246406 Emp error 0.4016339869281046\n",
      "25 LOG ERROR 0.6641748396560043 Emp error 0.40179738562091505\n",
      "26 LOG ERROR 0.6630747797372809 Emp error 0.39918300653594774\n",
      "27 LOG ERROR 0.6621280969201109 Emp error 0.4\n",
      "28 LOG ERROR 0.6613138695755171 Emp error 0.3996732026143791\n",
      "29 LOG ERROR 0.6606127125690279 Emp error 0.39869281045751637\n",
      "30 LOG ERROR 0.6600075509319568 Emp error 0.3983660130718954\n",
      "31 LOG ERROR 0.6595361454449229 Emp error 0.39591503267973854\n",
      "32 LOG ERROR 0.6591208208481799 Emp error 0.39477124183006534\n",
      "33 LOG ERROR 0.6587540331342224 Emp error 0.3931372549019608\n",
      "34 LOG ERROR 0.6584293402918795 Emp error 0.3926470588235294\n",
      "35 LOG ERROR 0.6581412337934529 Emp error 0.3918300653594771\n",
      "36 LOG ERROR 0.6578849938886514 Emp error 0.39166666666666666\n",
      "37 LOG ERROR 0.6576565684725033 Emp error 0.3918300653594771\n",
      "38 LOG ERROR 0.6574524722739035 Emp error 0.3918300653594771\n",
      "39 LOG ERROR 0.6572697026618679 Emp error 0.39101307189542484\n",
      "40 LOG ERROR 0.6571056688708438 Emp error 0.39052287581699346\n",
      "41 LOG ERROR 0.6569581321390641 Emp error 0.390359477124183\n",
      "42 LOG ERROR 0.656825154850412 Emp error 0.39019607843137255\n",
      "43 LOG ERROR 0.6567050572113118 Emp error 0.3895424836601307\n",
      "44 LOG ERROR 0.6565963803019738 Emp error 0.388562091503268\n",
      "45 LOG ERROR 0.6564978545556531 Emp error 0.38905228758169935\n",
      "46 LOG ERROR 0.6564083728742944 Emp error 0.3892156862745098\n",
      "47 LOG ERROR 0.6563269677072661 Emp error 0.38905228758169935\n",
      "48 LOG ERROR 0.6562527915151337 Emp error 0.3880718954248366\n",
      "49 LOG ERROR 0.6561851001208957 Emp error 0.3883986928104575\n",
      "50 LOG ERROR 0.6561232385203342 Emp error 0.3877450980392157\n",
      "51 LOG ERROR 0.6560666287836537 Emp error 0.3880718954248366\n",
      "52 LOG ERROR 0.6560147597332787 Emp error 0.38937908496732027\n",
      "53 LOG ERROR 0.6559671781289645 Emp error 0.38937908496732027\n",
      "54 LOG ERROR 0.655923481131072 Emp error 0.3892156862745098\n",
      "55 LOG ERROR 0.6558833098476466 Emp error 0.38937908496732027\n",
      "56 LOG ERROR 0.6558463438004114 Emp error 0.38872549019607844\n",
      "57 LOG ERROR 0.6558122961702414 Emp error 0.38676470588235295\n",
      "58 LOG ERROR 0.6557809097042532 Emp error 0.3872549019607843\n",
      "59 LOG ERROR 0.6557519531850475 Emp error 0.38676470588235295\n",
      "60 LOG ERROR 0.6557252183781229 Emp error 0.38594771241830067\n",
      "61 LOG ERROR 0.655703026257996 Emp error 0.3861111111111111\n",
      "62 LOG ERROR 0.6556823397924523 Emp error 0.38594771241830067\n",
      "63 LOG ERROR 0.6556630471218442 Emp error 0.38594771241830067\n",
      "64 LOG ERROR 0.6556450457634396 Emp error 0.3857843137254902\n",
      "65 LOG ERROR 0.6556282417044218 Emp error 0.38529411764705884\n",
      "66 LOG ERROR 0.6556125485963438 Emp error 0.384640522875817\n",
      "67 LOG ERROR 0.6555978870380538 Emp error 0.3854575163398693\n",
      "68 LOG ERROR 0.6555841839359724 Emp error 0.3861111111111111\n",
      "69 LOG ERROR 0.655571371932338 Emp error 0.38529411764705884\n",
      "70 LOG ERROR 0.6555593888931204 Emp error 0.384640522875817\n",
      "71 LOG ERROR 0.655548177448569 Emp error 0.384640522875817\n",
      "72 LOG ERROR 0.6555376845802632 Emp error 0.384640522875817\n",
      "73 LOG ERROR 0.6555278612492383 Emp error 0.38496732026143793\n",
      "74 LOG ERROR 0.6555186620605894 Emp error 0.38562091503267976\n",
      "75 LOG ERROR 0.655510044960419 Emp error 0.38529411764705884\n",
      "76 LOG ERROR 0.6555019709616224 Emp error 0.3854575163398693\n",
      "77 LOG ERROR 0.6554944038953158 Emp error 0.3854575163398693\n",
      "78 LOG ERROR 0.6554873101851845 Emp error 0.38562091503267976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7644065d2488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                        \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mepsilons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                        \u001b[0mproj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprojected\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                        debug= True)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aritrabiswas/Triplets/mypackage/algorithms.py\u001b[0m in \u001b[0;36mtriplet_algorithms\u001b[0;34m(f, S, X0, d, descent_alg, step_size_func, iters, epsilon, toler, proj, debug)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent_alg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdescent_alg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aritrabiswas/Triplets/mypackage/ste.py\u001b[0m in \u001b[0;36mste_loss_convex\u001b[0;34m(M, S, opt, descent_alg)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdescent_alg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full_grad'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mfull_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullGD_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mste_loss_triplet_gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfull_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aritrabiswas/Triplets/mypackage/new_utils.py\u001b[0m in \u001b[0;36mfullGD_X\u001b[0;34m(f, X, S)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mG\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aritrabiswas/Triplets/mypackage/ste.py\u001b[0m in \u001b[0;36mste_loss_triplet_gram\u001b[0;34m(M, q, opt)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtriplet_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplet_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscoreM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aritrabiswas/Triplets/mypackage/new_utils.py\u001b[0m in \u001b[0;36mscoreM\u001b[0;34m(M, q, opt)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m# pattern for computing gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         H = mat([[1.,0.,-1.],\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CONVEX STE FULL GRAD Single experiment\n",
    "M0 = np.random.randn(n,n)\n",
    "stats_convex_single_exp = []\n",
    "stats2 = triplet_algorithms(ste_loss_convex, \n",
    "                       triplets,\n",
    "                       M0,                       \n",
    "                       d,                            \n",
    "                       'full_grad', \n",
    "                        50,\n",
    "                       iters=5000,\n",
    "                       epsilon =epsilons[exp],\n",
    "                       proj=projected,\n",
    "                       debug= True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FUll Experimental setup\n",
    "stats_non_convex = []\n",
    "\n",
    "for epsilon in epsilons:\n",
    "    print('Epsilon', epsilon)\n",
    "    X0 = np.random.random((n,d))\n",
    "    stats1= triplet_algorithms(ste_loss, \n",
    "                       triplets,\n",
    "                       X0,                       \n",
    "                       d,\n",
    "                       'full_grad', \n",
    "                       20,\n",
    "                       iters=1000,\n",
    "                       epsilon = epsilon,\n",
    "                       proj=None,\n",
    "                       debug=False)\n",
    "    \n",
    "    stats_non_convex.append(stats1)\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment number i.e which level of accuracy \n",
    "exp = 0\n",
    "\n",
    "df = pd.DataFrame([\n",
    "#         stats_convex[3]['emp'],\n",
    "                   stats_non_convex[exp]['emp'],\n",
    "#                    stats3['emp'],\n",
    "#                     list(np.array(stats4['emp'])[epoch_inds])\n",
    "                  ]).T\n",
    "\n",
    "df.columns = [\n",
    "#     'Proj Grad: Full GD (constant stepsize, shrink each epoch)',\n",
    "              'Non convex: Full GD (constant stepsize, shrink each epoch)', \n",
    "#               'Proj Grad: SGD (constant stepsize)',\n",
    "#               'Non Convex: SGD (constant stepsize, shrink each epoch)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Epochs', fontsize=22)\n",
    "ax.set_title('Epsilon= {}'.format(epsilons[exp]), fontsize=22)\n",
    "ax.legend(fontsize=18);\n",
    "\n",
    "df = []\n",
    "for i in stats_non_convex:\n",
    "    df.append(sum(i['time_per_iter']))\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex FULL GD'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Non Convex SGD\n",
    "exp = 2\n",
    "stats4= triplet_algorithms(ste_loss, \n",
    "                           triplets,\n",
    "                           X0,                       \n",
    "                           d,\n",
    "                           'sgd', \n",
    "                           0.2,\n",
    "                           iters=5000,\n",
    "                           epsilon = epsilons[exp],\n",
    "                           proj=None,\n",
    "                           debug=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONVEX STE FULL GRAD Full exp set up\n",
    "M0 = np.random.randn(n,n)\n",
    "stats_convex = []\n",
    "for epsilon in epsilons:\n",
    "    stats2 = triplet_algorithms(ste_loss_convex, \n",
    "                       triplets,\n",
    "                       M0,                       \n",
    "                       d,                            \n",
    "                       'full_grad', \n",
    "                        600,\n",
    "                       iters=5000,\n",
    "                       epsilon =epsilon,\n",
    "                       proj=projected,\n",
    "                       debug= False)\n",
    "    \n",
    "    stats_convex.append(stats2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for i in stats_convex:\n",
    "    df.append(sum(i['time_per_iter']))\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats3 = triplet_algorithms(ste_loss_convex, \n",
    "#                             triplets,\n",
    "#                             M0,                       \n",
    "#                             d,                            \n",
    "#                             'sgd', \n",
    "#                             3,\n",
    "#                             iters=5000,\n",
    "#                             epsilon = 0.07625,\n",
    "#                             proj=projected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats2['emp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epoch_inds = np.linspace(0, len(stats4['emp'])-1, stats4['epoch_count'], dtype=int)\n",
    "\n",
    "df = pd.DataFrame([stats_convex[3]['emp'],\n",
    "                   stats_non_convex[3]['emp'],\n",
    "#                    stats3['emp'],\n",
    "                    list(np.array(stats4['emp'])[epoch_inds])\n",
    "                  ]).T\n",
    "df.columns = ['Proj Grad: Full GD (constant stepsize, shrink each epoch)',\n",
    "              'Non convex: Full GD (constant stepsize, shrink each epoch)', \n",
    "#               'Proj Grad: SGD (constant stepsize)',\n",
    "              'Non Convex: SGD (constant stepsize, shrink each epoch)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Epochs', fontsize=22)\n",
    "ax.set_title('Epsilon= {}'.format(0.07625), fontsize=22)\n",
    "ax.legend(fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "#                 stats2['emp'],\n",
    "#                 stats1['emp'],\n",
    "                   stats3['emp'],\n",
    "                   stats4['emp'],                   \n",
    "                  ]\n",
    "                 ).T\n",
    "df.columns = [\n",
    "#     'Proj Grad: Full GD (constant stepsize)',\n",
    "#               'Non convex full gradient descent (constant stepsize)', \n",
    "              'Proj Grad: SGD (constant stepsize)',\n",
    "              'Non Convex: SGD (constant stepsize)',              \n",
    "             ]\n",
    "\n",
    "ax = df.plot(figsize=(18,5), fontsize=18)\n",
    "ax.set_ylabel('0-1 loss', fontsize=22)\n",
    "ax.set_xlabel('Iterations of full gradient descent', fontsize=22)\n",
    "ax.legend(fontsize=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(stats1['time_per_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(stats2['time_per_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = []\n",
    "for i,j in zip(stats_non_convex,stats_convex):\n",
    "    df.append([sum(i['time_per_iter']), len(j['emp'])*stats_convex[0]['avg_time_per_iter']])\n",
    "    \n",
    "df = pd.DataFrame(df, columns=['Non convex', 'Convex- with projection'], index=np.linspace(0.005, 0.1,5))\n",
    "ax = df.plot(figsize=(18,8), fontsize=18, kind='bar')\n",
    "ax.set_ylabel('Time(sec)', fontsize=22)\n",
    "ax.set_xlabel('Error', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right');    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     print(len(stats_convex[i]['emp']))\n",
    "#     print(stats_convex[i]['time_per_iter'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
